{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2 - To do list gamification.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPSfn6pt3W6t1JI2we9kQIp"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"IeMx0IQSn3p1","executionInfo":{"status":"ok","timestamp":1606592026204,"user_tz":-330,"elapsed":2512,"user":{"displayName":"Nishad Singhi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsSrU5mF3Ahn7IIMcpjGcPBdFQYqZJZlxdqwU2eA=s64","userId":"11529316863200465619"}}},"source":["import sys\n","stdout = sys.stdout\n","from functools import reduce\n","sys.stdout = stdout"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oi4E7LaFli69"},"source":["Define the MDP (environment)"]},{"cell_type":"code","metadata":{"id":"_rFwCr8CnGoX","executionInfo":{"status":"ok","timestamp":1606592027996,"user_tz":-330,"elapsed":839,"user":{"displayName":"Nishad Singhi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsSrU5mF3Ahn7IIMcpjGcPBdFQYqZJZlxdqwU2eA=s64","userId":"11529316863200465619"}}},"source":["def getAllPossibleActions(currentState):\n","  if currentState == \"forget\" or currentState == \"done\":\n","    return []\n","  \n","  else:\n","    allValidTaskActions = [index+1 for index, value in enumerate(currentState) if value == 0]\n","    otherActions = [0, 6]\n","    allActions = allValidTaskActions+otherActions\n","    return allActions\n","\n","def transitionFunction(currentState, action):\n","  if action is 0:\n","    return {\"forget\": 0.025, currentState: 0.975}\n","\n","  elif action is 6:\n","    if currentState == (1, 1, 1, 1, 1):\n","      return {\"done\": 1}\n","    else:\n","      return {currentState: 1}\n","\n","  else:\n","    newState = list(currentState)\n","    newState[action-1] = 1\n","    return {tuple(newState): 1}\n","\n","def rewardFunction(currentState, action, nextState):\n","  if action is 6 and currentState != (1, 1, 1, 1, 1):\n","    return 0\n","\n","  if action is 0 and nextState == \"forget\":\n","      forgottenBonusEachTask = (0.25, 0.5, 0.75, 1, 1.75)\n","      totalBonus = 0\n","      for task in range(0, 5):\n","        if currentState[task] == 1:\n","          totalBonus += forgottenBonusEachTask[task]\n","      return totalBonus + 0.5\n","\n","  else:\n","    taskFairPrices = (0.67, 1.33, 2, 2.67, 3.33)\n","    # taskFairPrices = (3, 3.25, 2.25, 3, 1)\n","    taskRewards = [-fairPrice for fairPrice in taskFairPrices]\n","    allRewards = [0.5] + taskRewards + [20]\n","    return allRewards[action]"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E4sFLEcnluHk"},"source":["Code to generate all possible states "]},{"cell_type":"code","metadata":{"id":"kB-EtlvHrPv4","executionInfo":{"status":"ok","timestamp":1606592029895,"user_tz":-330,"elapsed":1492,"user":{"displayName":"Nishad Singhi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsSrU5mF3Ahn7IIMcpjGcPBdFQYqZJZlxdqwU2eA=s64","userId":"11529316863200465619"}}},"source":["def generateAllPermutations(startingArray, numToDoTasks):\n","    if numToDoTasks == 0:\n","      return [tuple(startingArray)]\n","\n","    allStates = []\n","    for bit in range(2):\n","      startingArrayWithNewBit = startingArray.copy()\n","      startingArrayWithNewBit.append(bit)\n","      allStates += generateAllPermutations(startingArrayWithNewBit, numToDoTasks-1)\n","\n","    return allStates\n","\n","generateAllStates = lambda numToDoTasks: generateAllPermutations([], numToDoTasks) + [\"forget\", \"done\"]"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w4cNUfX7uopx","executionInfo":{"status":"ok","timestamp":1606592030393,"user_tz":-330,"elapsed":1148,"user":{"displayName":"Nishad Singhi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsSrU5mF3Ahn7IIMcpjGcPBdFQYqZJZlxdqwU2eA=s64","userId":"11529316863200465619"}},"outputId":"6b18ff02-c281-4b9a-852d-c7a1df4e51cb"},"source":["allStates = generateAllStates(5)\n","print(allStates)\n","print(len(allStates))"],"execution_count":5,"outputs":[{"output_type":"stream","text":["[(0, 0, 0, 0, 0), (0, 0, 0, 0, 1), (0, 0, 0, 1, 0), (0, 0, 0, 1, 1), (0, 0, 1, 0, 0), (0, 0, 1, 0, 1), (0, 0, 1, 1, 0), (0, 0, 1, 1, 1), (0, 1, 0, 0, 0), (0, 1, 0, 0, 1), (0, 1, 0, 1, 0), (0, 1, 0, 1, 1), (0, 1, 1, 0, 0), (0, 1, 1, 0, 1), (0, 1, 1, 1, 0), (0, 1, 1, 1, 1), (1, 0, 0, 0, 0), (1, 0, 0, 0, 1), (1, 0, 0, 1, 0), (1, 0, 0, 1, 1), (1, 0, 1, 0, 0), (1, 0, 1, 0, 1), (1, 0, 1, 1, 0), (1, 0, 1, 1, 1), (1, 1, 0, 0, 0), (1, 1, 0, 0, 1), (1, 1, 0, 1, 0), (1, 1, 0, 1, 1), (1, 1, 1, 0, 0), (1, 1, 1, 0, 1), (1, 1, 1, 1, 0), (1, 1, 1, 1, 1), 'forget', 'done']\n","34\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T9lHuNYoloJF"},"source":["Value iteration algorithm to solve the MDP"]},{"cell_type":"code","metadata":{"id":"3C87im2wil2v","executionInfo":{"status":"ok","timestamp":1606592032991,"user_tz":-330,"elapsed":1253,"user":{"displayName":"Nishad Singhi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsSrU5mF3Ahn7IIMcpjGcPBdFQYqZJZlxdqwU2eA=s64","userId":"11529316863200465619"}}},"source":["class ValueIteration(object):\n","    def __init__(self, allStates, rewardFunction, transitionFunction, getAllPossibleActions, valueTable, convergenceTolerance, gamma):\n","        self.allStates = allStates.copy()\n","        self.rewardFunction = rewardFunction\n","        self.transitionFunction = transitionFunction\n","        self.getAllPossibleActions = getAllPossibleActions\n","        self.valueTable = valueTable.copy()\n","        self.convergenceTolerance = convergenceTolerance\n","        self.gamma = gamma\n","\n","    def getValueOfState(self, state):\n","        return self.valueTable[(state)]\n","\n","    def computeQValue(self, currentState, actionTaken):\n","        allNextStatesWithProbabilities = self.transitionFunction(currentState, actionTaken)\n","        possibleNextStates = list(allNextStatesWithProbabilities.keys())\n","        probabilitiesOfAllNextStates = list(allNextStatesWithProbabilities.values())\n","        return reduce(lambda x, y: x + y, [probabilityOfNextState * (self.rewardFunction(currentState, actionTaken, nextState) + self.gamma * self.getValueOfState(nextState)) for probabilityOfNextState, nextState in zip(probabilitiesOfAllNextStates, possibleNextStates)])\n","\n","    def updateValueOfState(self, state):\n","        possibleActions = self.getAllPossibleActions(state)\n","        if len(possibleActions) == 0:\n","          return 0\n","        QValuesForAllActions = [self.computeQValue(state, actionTaken) for actionTaken in possibleActions]\n","        return max(list(QValuesForAllActions))\n","\n","    def __call__(self):\n","        counter = 0\n","        while True:\n","            maxChangeInValue = 0\n","\n","            for state in self.allStates:\n","                currentState = state\n","                currentValueOfState = self.valueTable[currentState]\n","                updatedValueOfState = self.updateValueOfState(currentState)\n","                self.valueTable[state] = updatedValueOfState\n","                if abs(currentValueOfState - updatedValueOfState) > maxChangeInValue:\n","                    maxChangeInValue = abs(currentValueOfState - updatedValueOfState)\n","\n","            if maxChangeInValue < self.convergenceTolerance:\n","                break\n","\n","        stateValues = self.valueTable\n","        return stateValues"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a5pc2H8al3bO"},"source":["Run the value iteration algorithm "]},{"cell_type":"code","metadata":{"id":"e535EebHyGtq","executionInfo":{"status":"ok","timestamp":1606592035500,"user_tz":-330,"elapsed":1446,"user":{"displayName":"Nishad Singhi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsSrU5mF3Ahn7IIMcpjGcPBdFQYqZJZlxdqwU2eA=s64","userId":"11529316863200465619"}}},"source":["initialValueTable = {state: 0 for state in allStates}\n","convergenceTolerance = 1e-10\n","gamma = 0.95\n","valueIteration = ValueIteration(allStates, rewardFunction, transitionFunction, getAllPossibleActions, initialValueTable, convergenceTolerance, gamma)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"ESXdgJEWyZUF","executionInfo":{"status":"ok","timestamp":1606592036187,"user_tz":-330,"elapsed":870,"user":{"displayName":"Nishad Singhi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsSrU5mF3Ahn7IIMcpjGcPBdFQYqZJZlxdqwU2eA=s64","userId":"11529316863200465619"}}},"source":["finalValueTable = valueIteration()"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yiWsYW4NmL9r"},"source":["# **Function to compute optimal rewards**"]},{"cell_type":"code","metadata":{"id":"BKbPJlkPONst","executionInfo":{"status":"ok","timestamp":1606592038699,"user_tz":-330,"elapsed":1248,"user":{"displayName":"Nishad Singhi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsSrU5mF3Ahn7IIMcpjGcPBdFQYqZJZlxdqwU2eA=s64","userId":"11529316863200465619"}}},"source":["def computeOptimalIncentive(task):\n","  nextState = [0]*5\n","  nextState[task-1] = 1\n","  immediateReward = rewardFunction((0, 0, 0, 0, 0), task, nextState)\n","  currentStateValue = finalValueTable[(0, 0, 0, 0, 0)]\n","  nextStateValue = finalValueTable[tuple(nextState)]\n","\n","  return gamma*nextStateValue - currentStateValue"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zHKwO5FyQwPh","executionInfo":{"status":"ok","timestamp":1606592039874,"user_tz":-330,"elapsed":911,"user":{"displayName":"Nishad Singhi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsSrU5mF3Ahn7IIMcpjGcPBdFQYqZJZlxdqwU2eA=s64","userId":"11529316863200465619"}},"outputId":"37b61bcc-9efe-4c75-a4e7-ca19c135be1d"},"source":["print(\"task: \\t\\toptimal incentive\")\n","[print(\"task {}: \\t\\t{}\".format(task, round(computeOptimalIncentive(task), 3))) for task in range(1, 6)]"],"execution_count":10,"outputs":[{"output_type":"stream","text":["task: \t\toptimal incentive\n","task 1: \t\t0.626\n","task 2: \t\t1.253\n","task 3: \t\t1.858\n","task 4: \t\t2.432\n","task 5: \t\t2.97\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[None, None, None, None, None]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"0o34X-1ilot0"},"source":["# **TESTS**"]},{"cell_type":"code","metadata":{"id":"RhG8fMr345Fq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606592046926,"user_tz":-330,"elapsed":5154,"user":{"displayName":"Nishad Singhi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsSrU5mF3Ahn7IIMcpjGcPBdFQYqZJZlxdqwU2eA=s64","userId":"11529316863200465619"}},"outputId":"c95fd7f2-360e-4f18-8e5d-250346e76a38"},"source":["!pip install ddt\n","import unittest\n","from ddt import ddt, data, unpack"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Collecting ddt\n","  Downloading https://files.pythonhosted.org/packages/31/3b/a38bb1606c0b912cd53976369ac10334f6b5e96fa260eebc46fabe6a43bf/ddt-1.4.1-py2.py3-none-any.whl\n","Installing collected packages: ddt\n","Successfully installed ddt-1.4.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vfsQ6xoAS4lH","executionInfo":{"status":"ok","timestamp":1606592046929,"user_tz":-330,"elapsed":4504,"user":{"displayName":"Nishad Singhi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsSrU5mF3Ahn7IIMcpjGcPBdFQYqZJZlxdqwU2eA=s64","userId":"11529316863200465619"}}},"source":["@ddt\n","class TestEnvironment(unittest.TestCase):\n","  @data(((0, 0, 0, 0, 0), [1, 2, 3, 4, 5, 0, 6]),\n","        ((1, 0, 1, 0, 1), [2, 4, 0, 6]),\n","        ((1, 1, 1, 1, 1), [0, 6]))\n","  @unpack\n","  def testGetAllPossibleActions(self, currentState, trueAllPossibleActions):\n","    allPossibleActions = getAllPossibleActions(currentState)\n","    assert len(trueAllPossibleActions) == len(allPossibleActions)\n","    assert ([a == b for a, b in zip(trueAllPossibleActions, allPossibleActions)])\n","\n","  @data(((0, 0, 0, 0, 0), 0, {(0, 0, 0, 0, 0): 0.975, \"forget\": 0.025}),\n","        ((0, 0, 0, 0, 0), 1, {(1, 0, 0, 0, 0): 1}),\n","        ((0, 0, 0, 0, 0), 6, {(0, 0, 0, 0, 0): 1}),\n","        ((1, 0, 1, 0, 1), 2, {(1, 1, 1, 0, 1): 1}),\n","        ((1, 1, 1, 1, 1), 0, {(1, 1, 1, 1, 1): 0.975, \"forget\": 0.025}),\n","        ((1, 1, 1, 1, 1), 6, {\"done\": 1}))\n","  @unpack\n","  def testTransitionFunction(self, currentState, action, trueNextStateDict):\n","    nextStateDict = transitionFunction(currentState, action)\n","    self.assertDictEqual(trueNextStateDict, nextStateDict)\n","\n","  @data(((0, 0, 0, 0, 0), 2, (0, 1, 0, 0, 0), -1.33),\n","        ((0, 0, 0, 0, 0), 0, (0, 0, 0, 0, 0), 0.5),\n","        ((0, 0, 0, 0, 0), 0, \"forget\", 0.5),\n","        ((1, 0, 1, 0, 1), 0, (1, 0, 1, 0, 1), 0.5),\n","        ((1, 0, 1, 0, 1), 0, \"forget\", 3.25),\n","        ((1, 0, 1, 0, 1), 6, (1, 0, 1, 0, 1), 0),\n","        ((1, 1, 1, 1, 1), 6, \"done\", 20))\n","  @unpack\n","  def testRewardFunction(self, currentState, action, nextState, trueReward):\n","    reward = rewardFunction(currentState, action, nextState)\n","    self.assertAlmostEqual(reward, trueReward)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LuCU_5turc8R","executionInfo":{"status":"ok","timestamp":1606592046934,"user_tz":-330,"elapsed":3582,"user":{"displayName":"Nishad Singhi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhsSrU5mF3Ahn7IIMcpjGcPBdFQYqZJZlxdqwU2eA=s64","userId":"11529316863200465619"}},"outputId":"583fe0bd-3e31-4c06-b62a-15c6eddafb73"},"source":["@ddt\n","class TestValueIterationFunctions(unittest.TestCase):\n","  @data(((0, 0, 0, 0, 0), 2, {state: 0 for state in allStates}, -1.33),\n","        ((0, 1, 0, 0, 0), 0, {state: 0 for state in allStates}, 0.5125),\n","        ((1, 1, 1, 1, 1), 6, {state: 0 for state in allStates}, 20),\n","        ((0, 0, 0, 0, 0), 2, {state: 3 for state in allStates}, 1.52),\n","        ((1, 0, 1, 0, 1), 0, {state: 3 for state in allStates}, 3.41875),\n","        ((1, 0, 1, 0, 1), 6, {state: 3 for state in allStates}, 2.85))\n","  @unpack\n","  def testComputeQValue(self, currentState, actionTaken, valueTable, trueQValue):\n","    valueIteration = ValueIteration(allStates, rewardFunction, transitionFunction, getAllPossibleActions, valueTable, convergenceTolerance, gamma)\n","    QValue = valueIteration.computeQValue(currentState, actionTaken)\n","    self.assertAlmostEqual(trueQValue, QValue)\n","\n","  @data(((0, 0, 0, 0, 0), {state: 0 for state in allStates}, 0.5),\n","        ((1, 0, 1, 0, 1), {state: 3 for state in allStates}, 3.41875),\n","        ((1, 1, 1, 1, 1), {state: 3 for state in allStates}, 22.85),\n","        (\"forget\", {state: 3 for state in allStates}, 0),\n","        (\"done\", {state: 3 for state in allStates}, 0))\n","  @unpack\n","  def testUpdateValueOfState(self, state, valueTable, trueUpdatedValue):\n","    valueIteration = ValueIteration(allStates, rewardFunction, transitionFunction, getAllPossibleActions, valueTable, convergenceTolerance, gamma)\n","    updatedValue = valueIteration.updateValueOfState(state)\n","    self.assertAlmostEqual(trueUpdatedValue, updatedValue)\n","\n","unittest.main(argv=[''], verbosity=2, exit=False)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["testGetAllPossibleActions_1___0__0__0__0__0____1__2__3__4__5__0__6__ (__main__.TestEnvironment) ... ok\n","testGetAllPossibleActions_2___1__0__1__0__1____2__4__0__6__ (__main__.TestEnvironment) ... ok\n","testGetAllPossibleActions_3___1__1__1__1__1____0__6__ (__main__.TestEnvironment) ... ok\n","testRewardFunction_1___0__0__0__0__0___2___0__1__0__0__0____1_33_ (__main__.TestEnvironment) ... ok\n","testRewardFunction_2___0__0__0__0__0___0___0__0__0__0__0___0_5_ (__main__.TestEnvironment) ... ok\n","testRewardFunction_3___0__0__0__0__0___0___forget___0_5_ (__main__.TestEnvironment) ... ok\n","testRewardFunction_4___1__0__1__0__1___0___1__0__1__0__1___0_5_ (__main__.TestEnvironment) ... ok\n","testRewardFunction_5___1__0__1__0__1___0___forget___3_25_ (__main__.TestEnvironment) ... ok\n","testRewardFunction_6___1__0__1__0__1___6___1__0__1__0__1___0_ (__main__.TestEnvironment) ... ok\n","testRewardFunction_7___1__1__1__1__1___6___done___20_ (__main__.TestEnvironment) ... ok\n","testTransitionFunction_1 (__main__.TestEnvironment) ... ok\n","testTransitionFunction_2 (__main__.TestEnvironment) ... ok\n","testTransitionFunction_3 (__main__.TestEnvironment) ... ok\n","testTransitionFunction_4 (__main__.TestEnvironment) ... ok\n","testTransitionFunction_5 (__main__.TestEnvironment) ... ok\n","testTransitionFunction_6 (__main__.TestEnvironment) ... ok\n","testComputeQValue_1 (__main__.TestValueIterationFunctions) ... ok\n","testComputeQValue_2 (__main__.TestValueIterationFunctions) ... ok\n","testComputeQValue_3 (__main__.TestValueIterationFunctions) ... ok\n","testComputeQValue_4 (__main__.TestValueIterationFunctions) ... ok\n","testComputeQValue_5 (__main__.TestValueIterationFunctions) ... ok\n","testComputeQValue_6 (__main__.TestValueIterationFunctions) ... ok\n","testUpdateValueOfState_1 (__main__.TestValueIterationFunctions) ... ok\n","testUpdateValueOfState_2 (__main__.TestValueIterationFunctions) ... ok\n","testUpdateValueOfState_3 (__main__.TestValueIterationFunctions) ... ok\n","testUpdateValueOfState_4 (__main__.TestValueIterationFunctions) ... ok\n","testUpdateValueOfState_5 (__main__.TestValueIterationFunctions) ... ok\n","\n","----------------------------------------------------------------------\n","Ran 27 tests in 0.036s\n","\n","OK\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["<unittest.main.TestProgram at 0x7f808927f748>"]},"metadata":{"tags":[]},"execution_count":13}]}]}